<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />

<title>Hong Wang</title>

</head>
<body>

<a id="home" class="anchor"></a>
<div id="container"> 
<div class="container"> 

<table class="imgtable">
<tr>
<td> <a href="./"><img src="./Figures/Hong_2in.jpg" alt="" height="180px" /></a>&nbsp;</td>
<td align="left">
<p>
<font size="4">Hong Wang (王 红)</font><br />
<br />
Associate Professor (校青年拔尖人才支持计划、陕西省创新人才引进计划、中国科协青托人才)<br />
<br />
School of Life Science and Technology, Xi'an Jiaotong University, Xi'an, China<br />
<br />
Email: hongwang01@xjtu.edu.cn <br />
<br />
[<a class="p1" href="https://scholar.google.com/citations?user=I5RH0CwAAAAJ&amp;hl=en" target="_blank">Google Scholar</a>]
[<a class="p2" href="https://github.com/hongwang01" target="_blank">Github</a>]
[<a href="https://www.researchgate.net/profile/Hong-Wang-150" target="_blank">ResearchGate</a>]
[<a href="http://www.linkedin.com/in/hwang~DL" target="_blank">Linkedin</a>]
</p>
</td>
</tr></table>
<div class="infoblock">
    <div class="blocktitle"></div>
    <div class="blockcontent">
      <p><b><font color=blue>2025年学硕名额有1个，博士名额预计4月中旬可确定。2026年学硕、博士名额均有1个。欢迎自驱力强、数学基础好、编程能力强、具有一定医学背景的同学加入，请提前发邮件联系并附上成绩单和个人简历。团队长期招收访问学生和联合培养学生，欢迎合作联系。</font></b></p>
      <!--<p style="font-family: Kai;"><font color="#b22222">课题组现招收1名研究助理。<br>-->
      <!--</font></p>-->
    </div>
  </div>
<h2>Biography</h2>
<p> I am currently an Associate Professor at School of Life Science and Technology, Xi'an Jiaotong University, working with <a href="https://gr.xjtu.edu.cn/web/jhma75" target="_blank">Prof. Jianhua Ma</a> and <a href="https://gr.xjtu.edu.cn/en/web/dymeng" target="_blank">Prof. Deyu Meng</a>. Previously, I was a senior researcher at YouTu Lab@Tencent, Shenzhen,
    working with <a href="https://sites.google.com/site/yefengzheng/" target="_blank"> Prof. Yefeng Zheng (IEEE Fellow)</a>.
    I received my Ph.D. degree from School of Mathematics and Statistics, Xi'an Jiaotong University, China, in 2021, 
    under the supervision of <a href="https://gr.xjtu.edu.cn/en/web/dymeng" target="_blank">Prof. Deyu Meng</a>.
    Before that, I received my M.Sc degree under the supervision of <a href="https://person.zju.edu.cn/en/zhaoyangzhang/">Prof. Zhaoyang Zhang </a>from
    School of Information and Electronical Engineer, Zhejiang University, in 2018, and the B.S. degree from School of Communication and
    Information Engineer, Nanjing University of Posts and Telecommunications, in 2015.
  </p>


<h2>Research Interest</h2>
Currently, I work in the field of medical image processing and analysis, including CT/PET/MRI/Endoscopy reconstruction, medical image diagnosis, and multimodal analysis. Specifically, I mainly investigate how to combine
model-driven (domain knowledge-driven) method and data-driven deep learning techniques for effective and interpretable image processing. Recently, I focus on the following research topics:
<ul>
<li>CT/PET/MRI/Endoscopy Reconstruction</li>
<li>Deep Unfolding Image Restoration</li>
<li>Bayesian Methods in Image Processing</li>
<li>Foundation-model-driven Image Restoration </li>   
<li>Explainable Medical Analysis </li>
<li>Machine Learning (Continual Learning, Federated learning, Multi-task Learning)</li> 
</ul>


<h2>Research Experiences</h2>
<table class="imgtable">
<tr>
 <td align="left" style="width: 170px; padding-left: 45px;">
            <img src="./Figures/xjtu.png" alt="" width="80" height="80" style="display: block; margin: 0 auto;"/>
        </td>
    <td>
        <p><a href="https://open.youtu.qq.com" target="_blank" rel="noopener noreferrer">Xi'an Jiaotong University</a>, Xi'an, China</p>
        <p> Associate Professor, Mar. 2025 ~ present</p>
        <p> Team: <a href="https://gr.xjtu.edu.cn/web/jhma75" target="_blank"> Prof. Jianhua Ma</a> and <a href="https://gr.xjtu.edu.cn/en/web/dymeng" target="_blank">Prof. Deyu Meng</a></p>
    </td>
</tr>
</table>

<div style="height: 20px;"></div>

<table class="imgtable">
<tr>
    <td align="left">
            <img src="./Figures/Tencent-Youtu-lab.jpg" alt="" height="90px" width="170px"/>
    </td>
    <td>
        <p><a href="https://open.youtu.qq.com" target="_blank" rel="noopener noreferrer">YouTu Lab@Tencent</a>, Shenzhen, China</p>
        <p> Senior Researcher, Technical Expert (技术大咖), Feb. 2022 ~ Mar. 2025</p>
        <p> Supervisor: <a href="https://sites.google.com/site/yefengzheng/" target="_blank"> Prof. Yefeng Zheng (IEEE Fellow)</a></p>
    </td>
</tr>
</table>

<div style="height: 20px;"></div>

<table class="imgtable">
<tr>
    <td align="left">
            <img src="./Figures/Jarvislab.png" alt="" height="65px" width="170px"/>
    </td>
    <td>
        <p><a href="https://jarvislab.tencent.com/" target="_blank" rel="noopener noreferrer">Jarvis Lab@Tencent</a>, Shenzhen, China</p>
        <p>Research Intern (Tencent Rhino Bird Elite Talent Program), Sep. 2020 ~ Feb. 2022</p>
        <p>Supervisor: <a href="https://sites.google.com/site/yefengzheng/" target="_blank">Prof. Yefeng Zheng (IEEE Fellow)</a></p>
       
        <p>Honors: No.2 for Tencent Rhino Bird Elite Talent(<0.1%), Best Style Award(<0.1%)</p>
    </td>
</tr>  
</table>


<h2>News</h2>
<ul>
<li>[03/2025] Our STND for Nasopharyngeal Carcinoma Detection is accepted in The Lancet Digital Health 2025.      
<li>[03/2025] Our FSVG, a simple and better baseline, for visual grounding is accepted in ICME 2025. 
<li>[01/2025] Our AdaW for multiple-window metal artifact reduction is accepted in IEEE TMI 2025.  
<li>[10/2024] Honored to receive "2024 IEEE TMI Distinguished Reviewer".  
<!--<li>[07/2024] Our <a href="https://github.com/zmhhmz/ReSFU">ReSFU</a>, a universal feature upsampler, is available on arXiv.-->
<li>[05/2024] Our POCL for continual learning is accepted in ICML 2024.
<li>[04/2024] Our RER for continual learning is accepted in IEEE TMM 2024.
<li>[04/2024] Our <a href="https://github.com/pzq-xjtu/TRG-Net">TRGNet</a>, a controllable rain generator, is available on arXiv. 
<li>[04/2024] Honored to receive "2024 Excellent Doctoral Thesis of Xi'an Jiaotong University".
<li>[03/2024] Our Fed-CRFD for MRI reconstruction is accepted in IEEE JBHI 2024.
<li>[11/2023] Honored to be selected into the "9th China Association for Science and Technology Young Talent Promotion Project".
<li>[08/2023] Our extended OSCNet for CT metal artifact reduction is accepted in TMI 2023.
<li>[06/2023] Our MEPNet for joint sparse-view reconstruction and metal artifact reduction is accepted in MICCAI 2023.
<li>[06/2023] Our RAUNA for low-light image enhancement is accepted in TNNLS 2023.
<!--<li>[06/2023] Our Point SEGTR for endoscopic lesion segmentation is accepted in MedIA 2023.-->
<li>[03/2023] Our GPCIS for interactive segmentation is selected as a <a class="p1" target="_blank">highlight</a> at CVPR 2023 (10% of accepted papers, 2.5% of submissions).
<li>[03/2023] The dataset ``Synthesized DeepLesion'' has been released at <a href="https://github.com/hongwang01/SynDeepLesion" target="_blank">[SynDeepLesion]</a>.
<!-- <li>[02/2023] Two papers are accepted in CVPR 2023.</li>-->
<!-- <li>[02/2023] The pretrained-models for InDuDoNet and InDuDoNet+ have been released.</li>-->
<!-- <li>[02/2023] The code and pretrained-model for DICDNet have been released.</li>-->
<!-- <li>[01/2023] Our RCDNet for image deraining is accepted in TNNLS 2023.</li>-->
<!-- <li>[12/2022] Our InDuDoNet+ for CT metal artifact reduction is accepted in MedIA 2023.</li>-->
<!-- <li>[12/2022] One paper is accepted in AAAI 2023.</li>-->
<!-- <li>[07/2022] Our KXNet for image super-resolution is selected as an <a class="p1" target="_blank">oral</a> at ECCV 2022 (9.6% of accepted papers, 2.7% of submissions).</li>-->
<!-- <li>[06/2022] Our OSCNet for CT metal artifact reduction is accepted in MICCAI 2022.</li>-->
<!-- <li>[04/2022] Our ACDNet for CT metal artifact reduction is accepted in IJCAI 2022.</li>-->  
</ul>

    
<!-- Project -->
<a id="publications" class="anchor"></a>

<h2>Preprint </h2>

<table class="imgtable">

<!-- ReSFU -->
<tr>
<td><img class="proj_thumb" src="./Figures/ReSFU_arxiv.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title">A refreshed similarity-based upsampler for direct high-ratio feature upsampling</p>
<p class="pub_author">Minghao Zhou, <b>Hong Wang</b>*, Yefeng Zheng, Deyu Meng<br>
<font color="gray">arXiv:2407.02283, 2024</font><br>
[<a href= "https://arxiv.org/pdf/2407.02283" target="_blank">Paper</a>] 
[<a href="https://github.com/zmhhmz/ReSFU" target="_blank">Code</a>] 
</p> </td>
</tr>

<!-- CoSAM -->
<tr>
<td><img class="proj_thumb" src="./Figures/CoSAM_arxiv.png" alt="" height="90px"/>&nbsp;</td>
<td>
<p class="pub_title">Continual Learning for Segment Anything Model Adaptation</p>
<p class="pub_author">Jinglong Yang, Yichen Wu, Jun Cen, Wenjian Huang, <b>Hong Wang</b>*, Jianguo Zhang*<br>
<font color="gray">arXiv:2412.06418, 2024</font><br>
[<a href= "https://arxiv.org/pdf/2412.06418" target="_blank">Paper</a>] 
[<a href="https://github.com/yangjl1215/CoSAM" target="_blank">Code</a>] 
</p> </td>
</tr>

</table>

<h2>Selected Publications
<a style="color:Black" class="p1" href="https://scholar.google.com/citations?user=I5RH0CwAAAAJ&amp;hl=en" target="_blank">
    <font size="2"> [Full List]</font></a> <font size="2">(^Co-first author; *Corresponding author)</font>
</h2>

<table class="imgtable">

<!-- Lancet 2025, STND-->
<tr>
<td><img class="proj_thumb" src="./Figures/Lancet25_STND.png.PNG" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">Artificial Intelligence Assisted Detection of Nasopharyngeal Carcinoma on Endoscopic Images: A National Multi-Center Evidence Study</p>
<p class="pub_author">Yuxuan Shi^, Zhen Li^, Li Wang^, <b>Hong Wang</b>^, Xiaofeng Liu, Dantong Gu, Xiao Chen, Xueli Liu, et al.<br>
The Lancet Digital Health, 2025.<br>
</p> </td>
</tr>

<!-- ICME 2025, FSVG-->
<tr>
<td><img class="proj_thumb" src="./Figures/ICME25_FSVG.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">A Simple and Better Baseline for Visual Grounding</p>
<p class="pub_author">Jingchao Wang, Wenlong Zhang, Dingjiang Huang*, <b>Hong Wang</b>*, Yefeng Zheng<br>
IEEE International Conference on Multimedia & Expo (<b>ICME</b>), 2025.<br>
</p> </td>
</tr>
    
<!-- TMI 2025, AdaW-->
<tr>
<td><img class="proj_thumb" src="./Figures/TMI2025-AdaW.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">Adaptive Weighting based Metal Artifact Reduction in CT images</p>
<p class="pub_author"><b>Hong Wang</b>^, Yichen Wu^, Yongbo Wang, Dong Wei, Xian Wu, Jianhan Ma, Yefeng Zheng<br>
IEEE Transactions on Medical Imaging (<b>TMI</b>), 2025.<br>
</p> </td>
</tr>


    
<!-- ICML 2024, POCL-->
<tr>
<td><img class="proj_thumb" src="./Figures/POCL_ICML2024.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">Mitigating Catastrophic Forgetting in Online Continual Learning by Modeling Previous Task Interrelations</p>
<p class="pub_author">Yichen Wu^, <b>Hong Wang</b>^, Peilin Zhao, Yefeng Zheng, Ying Wei, Long-Kai Huang<br>
International Conference on Machine Learning (<b>ICML</b>), 2024.<br>
[<a href= "https://openreview.net/forum?id=olbTrkWo1D" target="_blank">Paper</a>]
<!-- [<a href="https://github.com/hongwang01/OSCNet" target="_blank">Code</a>] -->
</p> </td>
</tr>

    
<!-- TMM 2024, RER-->
<tr>
<td><img class="proj_thumb" src="./Figures/RER_TMM2024.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">Relational Experience Replay: Continual Learning by Adaptively Tuning Task-wise Relationship</p>
<p class="pub_author">Quanziang Wang, Renzhen Wang, Yuexiang Li, Dong Wei, <b>Hong Wang</b>, Kai Ma, Yefeng Zheng, Deyu Meng<br>
IEEE Transactions on Multimedia (<b>TMM</b>), 2024.<br>
[<a href= "https://arxiv.org/pdf/2112.15402" target="_blank">Paper</a>]
<!-- [<a href="https://github.com/hongwang01/OSCNet" target="_blank">Code</a>] -->
</p> </td>
</tr>

    
<!-- JBHI 2024, Fed-CRFD-->
<tr>
<td><img class="proj_thumb" src="./Figures/Fed-CRFD_JBHI2024.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">Cross-Modal Vertical Federated Learning for MRI Reconstruction</p>
<p class="pub_author">Yunlu Yan^, <b>Hong Wang</b>^, Yawen Huang, Nanjun He, Lei Zhu, Yong Xu, Yuexiang Li, Yefeng Zheng<br>
IEEE Journal of Biomedical and Health Informatics (<b>JBHI</b>), 2024.<br>
[<a href= "https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10417111" target="_blank">Paper</a>]
<!-- [<a href="https://github.com/hongwang01/OSCNet" target="_blank">Code</a>] -->
</p> </td>
</tr>


<!-- TMI 2023, OSCNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/OSCNet_MICCAI2022.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">OSCNet: Orientation-Shared Convolutional Network for CT Metal Artifact Learning</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Dong Zeng, Jianhua Ma, Deyu Meng, Yefeng Zheng<br>
IEEE Transactions on Medical Imaging (<b>TMI</b>), 2023.<br>
[<a href= "https://drive.google.com/file/d/1ach658FTosbD7h3BHopZM6oj0O-890Uj/view?usp=drive_link" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/OSCNet" target="_blank">Code</a>]
</p> </td>
</tr>


    
<!--MICCAI 2023-->
<tr>
<td><img class="proj_thumb" src="./Figures/MICCAI2023_MEPNet.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">MEPNet: A Model-Driven Equivariant Proximal Network for Joint Sparse-View Reconstruction and Metal Artifact Reduction in CT Images</p>
<p class="pub_author"><b>Hong Wang</b>*, Minghao Zhou, Dong Wei, Yefeng Zheng<br>
International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2023.<br>
[<a href= "https://drive.google.com/file/d/1aSkXJtmEsttFroe9DaVxMo5CoSsTImi8/view?usp=drive_link" target="_blank">Paper</a>] 
[<a href="https://github.com/hongwang01/MEPNet" target="_blank">Code</a>] 
</p> </td>
</tr>

    
<!--TNNLS 2023-->
<tr>
<td><img class="proj_thumb" src="./Figures/TNNLS2023_RAUNA.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Low-light Image Enhancement by Retinex-based Algorithm Unrolling and Adjustment</p>
<p class="pub_author">Xinyi Liu, Qi Xie, Qian Zhao, <b>Hong Wang</b>, Deyu Meng<br>
IEEE Transactions on Neural Networks and Learning Systems</i> (<b>TNNLS</b>), 2023.<br>
[<a href= "https://arxiv.org/pdf/2202.05972.pdf" target="_blank">Paper</a>]
</p> </td>
</tr>
    
<!--MedIA 2023-->
<tr>
<td><img class="proj_thumb" src="./Figures/Point SEGTR_MedIA23.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">A Deep Weakly Semi-Supervised Framework for Endoscopic Lesion Segmentation</p>
<p class="pub_author">Yuxuan Shi^, <b>Hong Wang</b>^*, Haoqin Ji, Haozhe Liu, Nanjun He, Dong Wei, Qi Dai, Jianrong Wu, Xinrong Chen*, Yefeng Zheng, Hongmeng Yu*<br>
Medical Image Analysis (<b>MedIA</b>), 2023.<br>
</p> </td>
</tr>
    
    
    
<!--CVPR 2023-->
<tr>
<td><img class="proj_thumb" src="./Figures/GPCIS_CVPR2023.jpg" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Interactive Segmentation as Gaussian Process Classification</p>
<p class="pub_author">Minghao Zhou, <b>Hong Wang</b>*, Qian Zhao, Deyu Meng, Yefeng Zheng<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<a class="p1" target="_blank">highlight</a>)</i>(<b>CVPR</b>), 2023.<br>
[<a href= "https://arxiv.org/abs/2302.14578" target="_blank">Paper</a>] 
[<a href="https://github.com/zmhhmz/GPCIS_CVPR2023" target="_blank">Code</a>] 
</p> </td>
</tr>
    


<!--TNNLS 2023-->
<tr>
<td><img class="proj_thumb" src="./Figures/DRCDNet_TNNLS2022.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">RCDNet: An Interpretable Rain Convolutional Dictionary Network for Single Image Deraining</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Qian Zhao, Yong Liang, Yefeng Zheng, Deyu Meng<br>
IEEE Transactions on Neural Networks and Learning Systems</i> (<b>TNNLS</b>), 2023.<br>
[<a href= "https://arxiv.org/abs/2107.06808" target="_blank">Paper</a>] 
[<a href="https://github.com/hongwang01/DRCDNet" target="_blank">Code</a>] 
</p> </td>
</tr>


<!--MedIA 2023-->
<tr>
<td><img class="proj_thumb" src="./Figures/InDuDoNet+_MedIA2022.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">InDuDoNet+: A Deep Unfolding Dual Domain Network for Metal Artifact Reduction in CT Images</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Haimiao Zhang, Deyu Meng, Yefeng Zheng<br>
Medical Image Analysis</i>(<b>MedIA</b>), 2023.<br>
[<a href= "https://arxiv.org/pdf/2112.12660.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/InDuDoNet_plus" target="_blank">Code</a>]
</p> </td>
</tr>





<!--ECCV 2022-->
<tr>
<td><img class="proj_thumb" src="./Figures/KXNet_ECCV2022.png" alt="" height="90px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">KXNet: A Model-Driven Deep Neural Network for Blind Super-Resolution</p>
<p class="pub_author">Jiahong Fu, <b>Hong Wang</b>, Qi Xie, Qian Zhao, Deyu Meng, Zongben Xu<br>
European Conference on Computer Vision (<a class="p1" target="_blank">Oral</a>)</i>(<b>ECCV</b>), 2022.<br>
[<a href= "https://github.com/jiahong-fu/KXNet" target="_blank">Paper</a>]
[<a href="https://github.com/jiahong-fu/KXNet" target="_blank">Code</a>]
</p> </td>
</tr>    

<!-- MICCAI 2022, OSCNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/OSCNet_MICCAI2022.png" alt="" height="50px" width="180px" />&nbsp;</td>
<td>
<p class="pub_title">Orientation-Shared Convolution Representation for CT Metal Artifact Learning</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Deyu Meng, Yefeng Zheng<br>
International Conference on Medical Image Computing and Computer Assisted Intervention (<b>MICCAI</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2212.13166.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/OSCNet" target="_blank">Code</a>]
</p> </td>
</tr>



<!-- IJCAI 2022, ACDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/ACDNet_IJCAI2022.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Adaptive Convolutional Dictionary Network for CT Metal Artifact Reduction</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Deyu Meng, Yefeng Zheng<br>
31st International Joint Conference on Artificial Intelligence (<b>IJCAI</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/2205.07471.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/ACDNet" target="_blank">Code</a>]
</p> </td>
</tr>

    
<!--SCIS 2022 Survey-->
<tr>
<td><img class="proj_thumb" src="./Figures/Survey_SCIS2022.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Survey on Rain Removal From Videos or A Single Image</p>
<p class="pub_author"><b>Hong Wang</b>, Yichen Wu, Minghan Li, Qian Zhao, Deyu Meng<br>
SCIENCE CHINA Information Sciences</i>(<b>SCIS</b>), 2022.<br>
[<a href= "https://arxiv.org/pdf/1909.08326.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/Video-and-Single-Image-Deraining" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- TMI 2021, DICDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/DICDNet_TMI2021.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">DICDNet: Deep Interpretable Convolutional Dictionary Network for Metal Artifact Reduction in CT Images</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Nanjun He, Kai Ma, Deyu Meng, Yefeng Zheng<br>
IEEE Transactions on Medical Imaging (<b>TMI</b>), 2021.<br>
[<a href= "https://github.com/hongwang01/DICDNet" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/DICDNet" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- MICCAI 2021, InDuDoNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/InDuDoNet_MICCAI2021.png" alt="" height="85px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">InDuDoNet: An Interpretable Dual Domain Network for CT Metal Artifact Reduction</p>
<p class="pub_author"><b>Hong Wang</b>, Yuexiang Li, Haimiao Zhang, Kai Ma, Deyu Meng, Yefeng Zheng<br>
International Conference on Medical Image Computing and Computer Assisted Intervention  (<b>MICCAI</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2109.05298.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/InDuDoNet" target="_blank">Code</a>]
</p> </td>
</tr>


<!-- CVPR 2021, VRGNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/VRGNet_CVPR2021.png" alt="" height="70px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">From Rain Generation to Rain Removal</p>
<p class="pub_author"><b>Hong Wang</b>^, Zongsheng Yue^, Qi Xie, Qian Zhao, Yefeng Zheng, Deyu Meng<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2021.<br>
[<a href= "https://openaccess.thecvf.com/content/CVPR2021/html/Wang_From_Rain_Generation_to_Rain_Removal_CVPR_2021_paper.html" target="_blank">Paper</a>] 
[<a href="https://github.com/hongwang01/VRGNet" target="_blank">Code</a>] 
</p> </td>
</tr>
    
<!-- KBS 2021 SRNet-->
<!-- <tr>
<td><img class="proj_thumb" src="./Figures/SRNet_KBS2021.png" alt="" height="116px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Structural Residual Learning for Single Image Rain Removal</p>
<p class="pub_author"><b>Hong Wang</b>, Yichen Wu, Qi Xie, Qian Zhao, Yong Liang, Shijun Zhang, Deyu Meng<br>
Knowledge-Based Systems</i> (<b>KBS</b>), 2021.<br>
[<a href= "https://arxiv.org/pdf/2005.09228.pdf" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/SRNet" target="_blank">Code</a>]
</p> </td>
</tr> -->

<!-- CVPR 2020, RCDNet-->
<tr>
<td><img class="proj_thumb" src="./Figures/RCDNet_CVPR2020.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">A Model-driven Deep Neural Network for Single Image Rain Removal</p>
<p class="pub_author"><b>Hong Wang</b>^, Qi Xie^, Qian Zhao, Deyu Meng<br>
IEEE International Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2020.<br>
[<a href= "https://openaccess.thecvf.com/content_CVPR_2020/html/Wang_A_Model-Driven_Deep_Neural_Network_for_Single_Image_Rain_Removal_CVPR_2020_paper.html" target="_blank">Paper</a>]
[<a href="https://github.com/hongwang01/RCDNet" target="_blank">Code</a>]
</p> </td>
</tr>

 <!-- IJMLC 2020-->
<!-- <tr>
<td><img class="proj_thumb" src="./Figures/IJMCL2020.png" alt="" height="80px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Single Image Rain Streaks Removal: A Review and An Exploration</p>
<p class="pub_author"><b>Hong Wang</b>, Qi Xie, Yichen Wu, Qian Zhao, Deyu Meng<br>
International Journal of Machine Learning and Cybernetics (<b>IJMLC</b>), 2020.<br>
[<a href= "https://link.springer.com/article/10.1007/s13042-020-01061-2" target="_blank">Paper</a>]
</p> </td>
</tr> -->

<!-- NC 2020, GAN-->
<!-- <tr>
<td><img class="proj_thumb" src="./Figures/Neurocomputing2020.png" alt="" height="90px" width="180px"/>&nbsp;</td>
<td>
<p class="pub_title">Selective Generative Adversarial Network for Raindrop Removal From A Single Image</p>
<p class="pub_author">Mingwen Shao, Le Li, <b>Hong Wang</b>, Deyu Meng<br>
Neurocomputing (<b>NC</b>), 2020.<br>
[<a href= "https://www.sciencedirect.com/science/article/abs/pii/S0925231220315861" target="_blank">Paper</a>]
</p> </td>
</tr> -->

<table>

<!--Honors -->
<a id="honors" class="anchor"></a>
<h2>Selected Honors</h2>

<p>2020.09-2025.03 (Tencent Technology (Shenzhen) Co., Ltd.)[实习免试正式录用为校招技术大咖]: </p>
<font size="2">
<ul>
<li>2024Q4 No.1 of Tencent Micro-Innovation Award | 腾讯微创新奖第一名</li>  
<li>Selected in the 2023 "9th China Association for Science and Technology Young Talent Promotion Project" (TOP 5) | 第九届中国科协青年人才托举项目(集团仅5人)</li>
<li>2023 Outstanding Mentor Award of Tencent Rhino Bird Elite Talent | 腾讯犀牛鸟全国精英人才培养计划杰出导师奖
<li>2023 Tencent Party Committee "Excellent Communist Party Member" (<5%) | 腾讯集团优秀共产党员</li>
<li>2023H1 Outstanding Contributor (TOP 1 in Group) | 腾讯5星杰出员工</li>    
<li>2023Q2 Winner of Technological Innovation Award of Jarvis Lab, Tencent | 天衍实验室技术创新奖</li>   
<li>2023Q1 No.2 of Tencent Micro-Innovation Award (2/19) | 腾讯微创新奖第二名</li>      
<li>2022 Tencent Patent Gold Award (TOP 2) | 腾讯年度专利金奖(集团2/5000+)</li>    
<li>2022Q3 No.6 of Tencent Micro-Innovation Award (6/21) | 腾讯微创新奖第六名</li>  
<li>2021 No.2 for Tencent Rhino Bird Elite Talent(<0.1%), Best Style Award(<0.1%) | 腾讯犀牛鸟全国精英人才培养计划第二名及个人风采奖</li>
<li>2020 Tencent Rhino Bird Elite Talent Program | 被选拔进入腾讯犀牛鸟全国精英人才培养计划</li>
</ul>
</font>
    
<p>2018.09-2021.12 (Xi'an Jiaotong University)[第一名跨专业考入]: </p>
<font size="2">
<ul>
<li>2024 Excellent Doctoral Thesis of Xi'an Jiaotong University | 西安交通大学优秀博士论文</li>
<li>Outstanding Graduate Student of Shaanxi Province | 陕西省优秀毕业研究生</li>
<li>National Scholarship for Graduate Students (<2%) (<b>highest national wide scholarship for students in China</b>) | 博士研究生国奖</li>
<li>Academic star best Popularity Award(<b>Top 1 in Xi'an Jiaotong University</b>) | 学术之星最佳风采奖</li>
<li>Academic star nomination award (<b>Top 13 in Xi'an Jiaotong University</b>) | 学术之星最佳提名奖</li>
<li>Huawei Scholarship (<1%) | 华为奖学金</li>
<li>Outstanding graduate student of Xi’an Jiaotong University(<b>2 times</b>) | 校优秀毕业研究生</li>
<li>1st prize for Scholarship of Xi’an Jiaotong University | 校一等奖学金</li>
<!-- <li>3rd prize for National Graduate Mathematical modeling Contest (<5%) | 研究生数</li>-->
</ul>
</font>

<p>2015.09-2018.03 (Zhejiang University)[第一名保送]: </p>
<font size="2">
<ul>
<li>Outstanding graduate student of Zhejiang University | 校优秀毕业研究生</li>
<li>National Scholarship for Graduate Students (<2%) (<b>highest national wide scholarship for students in China</b>) | 硕士研究生国奖</li>
<li>Outstanding Graduate Student Cadre of Zhejiang University | 校优秀研究生干部</li>
<li>Merit Graduate Student of Zhejiang University(<b>2 times</b>) | 校优秀研究生(2次) </li>
<li>Samsung Scholarship (<3%) | 三星奖学金</li>
<li>1st prize for National Graduate Electronical Design Competition (<1%) | 全国研究生电子设计竞赛一等奖</li>
</ul>
</font>

<p>2011.09-2015.06 (Nanjing University of Posts and Telecommunications)[省Top 1%考入]: </p>
<font size="2">
<ul>
<li>Outstanding undergraduate student of NUPT | 校优秀毕业生</li>
<li>National Scholarship for Undergraduate Students (<1%, <b>3 times</b>) (<b>highest national wide scholarship for students in China</b>) | 本科国奖(三次)</li>
<li>China Telecom Scholarship (<1%) | 中国电信飞Young奖学金</li>
<li>Hengtong First Prize Scholarship (<1%) | 亨通一等奖学金</li>
<li>1st prize (Meritorious Winner) of International Mathematical Contest in Modeling (MCM) (<1%) | 数模美赛一等奖(队长)</li>
<li>Provincial Merit Student Award (<1%) | 江苏省三好学生</li>
<li>Pacemaker to Creative Student of NUPT(<b>Top10 in NUPT</b>) | 校创新标兵(全校仅10人)</li>
<li>1st prize for Advanced Mathematics Competition in Jiangsu Province (<5%) | 江苏省高数竞赛一等奖</li>
<li>1st prize for scholarship of NUPT (<5%, <b>3 times</b>) | 校一等奖学金(三次)</li>
<li>Pacemaker to Merit Student of NUPT (<5%, <b>3 times</b>) | 校三好学生(三次)</li>
</ul>
</font>

<!-- Talks-->
<a id="talks" class="anchor"></a>
<h2>Talks</h2>
<font size="2"> 
<ul>
<li> 2024.12.15 <a href="https://mp.weixin.qq.com/s/mYuCuRl0WI1btesSleBnow" target="_blank">中国医学人工智能大会</a></li>
<li> 2024.09.28 <a href="https://math.scu.edu.cn/info/1257/4071.htm" target="_blank">太赫兹CT成像学术研讨会</a></li>
<li> 2022.12.11 <a href="https://mp.weixin.qq.com/s/ZsGQ1uoaJeR0fIg5gmJVHA" target="_blank">VALSE Student Webinar "面向底层视觉任务的基础算法" 青年学者论坛</a></li>
<li> 2022.11.13 <a href="https://mp.weixin.qq.com/s/4mCA7pvlz3Tqn_zavb-tIg" target="_blank">中国体视学学会智能成像分会第一届有方青年学术论坛，<a href="https://pan.baidu.com/s/1Y0Hrfeg-g3kGCTvO5A-8pw" target="_blank">[PPT]</a>, password: abcd </li>
</ul>
</font>

<!-- Services -->
<a id="services" class="anchor"></a>
<h2>Services</h2>
<p>Journal Reviewer:  </p>
<font size="2"> 
<ul>
<li>IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)</li>
<li>IEEE Transactions on Medical Imaging (TMI)</li>
<li>IEEE Transactions on Image Processing (TIP)</li>
<li>IEEE Transactions on Neural Networks and Learning Systems (TNNLS)</li>
<li>IEEE Transactions on Communications (TCOM)</li>
<li>IEEE Transactions on Circuits and Systems for Video Technology (TCSVT)</li>
<li>IEEE Transactions on Information Forensics & Security (T-IFS)</li>
<li>IEEE Transactions on Computational Imaging (TCI)</li>
<li>SCIENCE CHINA Information Sciences (SCIS)</li>
<li>Knowledge Based Systems (KBS)</li>   
<li>Scientific Reports</li> 
<li>Neurocomputing</li> 
<li>Magnetic Resonance Imaging</li>
<li>IEEE Signal Processing Letters</li>
<li>Signal, Image and Video Processing</li> 
</ul>
</font>


<p>Conference Reviewer: </p>
<font size="2"> 
<ul>
<li>IEEE International Conference on Computer Vision and Pattern Recognition (CVPR)</li>
<li>IEEE International Conference on Computer Vision (ICCV)</li>
<li>European Conference on Computer Vision (ECCV)</li>
<li>Association for the Advancement of Artificial Intelligence (AAAI)</li>
<li>International Joint Conference on Artificial Intelligence (IJCAI) (<b>Outstanding SPC for IJCAI2019</b>)</li>
<li>International Conference on Medical Image Computing and Computer-Assisted Intervention (MICCAI)</li>
<li>2024 NeurIPS workshop on AIM-FM</li>
<li>2024 NeurIPS workshop on Compositional Learning </li>    
</ul>
</font>

<div id="footer">
<div id="footer-text">
<!--
All Rights Reserved. Part of page is generated by <a href="http://jemdoc.jaboc.net/">jemdoc</a>.
-->

</div>
</div>
<a href="https://clustrmaps.com/site/1b743"  title="Visit tracker"><img src="//www.clustrmaps.com/map_v2.png?d=7HOnPG-tgP2NBIq9v142wI5iM0mQ3OwnnIRnYxx5SdI&cl=ffffff" width=1pt height=1pt/></a>
</body>
</html>
